---
layout: post
title: "Data Imputation Brief Review"
date: 2021-03-02 20:48:00
author: "Shawn"
header-style: text
catalog: true
tags:
  - 数据补全
  - Matrix Factorization
---

最近在赶数据补全的工作，这里把一些知识点补习一下

## Tensor-based imputation

#### 矩阵基本知识—从特征值、特征向量到PCA

我们知道，矩阵乘法对应了一个变换，是把任意一个向量变成另一个方向或长度都大多不同的新向量。在这个变换的过程中，原向量主要发生旋转、伸缩的变化。**如果矩阵对某一个向量或某些向量只发生伸缩变换，不对这些向量产生旋转的效果，那么这些向量就称为这个矩阵的特征向量，伸缩的比例就是特征值。**

实际上，上述的一段话既讲了矩阵变换特征值及特征向量的几何意义（图形变换）也讲了其物理含义。物理的含义就是运动的图景：特征向量在一个矩阵的作用下作伸缩运动，伸缩的幅度由特征值确定。特征值大于*1*，所有属于此特征值的特征向量身形暴长；特征值大于*0*小于*1*，特征向量身形猛缩；特征值小于*0*，特征向量缩过了界，反方向到*0*点那边去了。

